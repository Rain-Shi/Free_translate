"""
æµ‹è¯•AIæ™ºèƒ½è¯†åˆ«ç‰¹æ®Šåç§°åŠŸèƒ½
"""

from smart_translator import SemanticTranslator
import json

def test_ai_special_name_identification():
    """æµ‹è¯•AIæ™ºèƒ½è¯†åˆ«ç‰¹æ®Šåç§°åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•AIæ™ºèƒ½è¯†åˆ«ç‰¹æ®Šåç§°åŠŸèƒ½")
    print("=" * 60)
    
    # æ¨¡æ‹ŸAPIå¯†é’¥ï¼ˆå®é™…ä½¿ç”¨æ—¶éœ€è¦çœŸå®å¯†é’¥ï¼‰
    api_key = "test-key"
    
    # åˆ›å»ºç¿»è¯‘å™¨
    translator = SemanticTranslator(api_key)
    
    # æµ‹è¯•æ–‡æœ¬ï¼ŒåŒ…å«å„ç§ç‰¹æ®Šåç§°
    test_cases = [
        {
            "text": "The naiveHobo/InvoiceNet library is used for invoice processing.",
            "expected": ["naiveHobo/InvoiceNet"],
            "description": "GitHubåº“åè¯†åˆ«"
        },
        {
            "text": "We use microsoft/TypeScript and facebook/react for development.",
            "expected": ["microsoft/TypeScript", "facebook/react"],
            "description": "å¤šä¸ªGitHubåº“åè¯†åˆ«"
        },
        {
            "text": "The project uses TensorFlow, PyTorch, and Scikit-learn for machine learning.",
            "expected": ["TensorFlow", "PyTorch", "Scikit-learn"],
            "description": "æœºå™¨å­¦ä¹ æ¡†æ¶è¯†åˆ«"
        },
        {
            "text": "OpenAI developed ChatGPT and GitHub Copilot for AI assistance.",
            "expected": ["OpenAI", "ChatGPT", "GitHub Copilot"],
            "description": "AIäº§å“åç§°è¯†åˆ«"
        },
        {
            "text": "The API uses HTTP, JSON, and OAuth for authentication.",
            "expected": ["HTTP", "JSON", "OAuth"],
            "description": "åè®®å’Œæ ‡å‡†è¯†åˆ«"
        },
        {
            "text": "Python and JavaScript are popular programming languages.",
            "expected": ["Python", "JavaScript"],
            "description": "ç¼–ç¨‹è¯­è¨€è¯†åˆ«"
        },
        {
            "text": "Google, Microsoft, and Amazon are tech giants.",
            "expected": ["Google", "Microsoft", "Amazon"],
            "description": "å…¬å¸åç§°è¯†åˆ«"
        }
    ]
    
    print("ğŸ“ æµ‹è¯•ç”¨ä¾‹:")
    for i, case in enumerate(test_cases, 1):
        print(f"{i}. {case['description']}: {case['text']}")
    
    print("\nğŸ” AIè¯†åˆ«ç»“æœ:")
    for i, case in enumerate(test_cases, 1):
        print(f"\n{i}. {case['description']}")
        print(f"åŸæ–‡: {case['text']}")
        
        try:
            # ä½¿ç”¨AIè¯†åˆ«ç‰¹æ®Šåç§°
            identified_names = translator._identify_special_names_with_ai(case['text'])
            print(f"AIè¯†åˆ«ç»“æœ: {identified_names}")
            
            # æ£€æŸ¥è¯†åˆ«å‡†ç¡®æ€§
            correct_identifications = [name for name in identified_names if name in case['text']]
            print(f"æ­£ç¡®è¯†åˆ«: {correct_identifications}")
            
            # æ£€æŸ¥æ˜¯å¦é—æ¼äº†æœŸæœ›çš„åç§°
            missed_names = [name for name in case['expected'] if name not in identified_names]
            if missed_names:
                print(f"é—æ¼çš„åç§°: {missed_names}")
            
            print("-" * 50)
            
        except Exception as e:
            print(f"âŒ è¯†åˆ«å¤±è´¥: {str(e)}")
    
    print("\nâœ… AIæ™ºèƒ½è¯†åˆ«åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")

def test_ai_protection_workflow():
    """æµ‹è¯•AIä¿æŠ¤å·¥ä½œæµç¨‹"""
    print("\nğŸ§ª æµ‹è¯•AIä¿æŠ¤å·¥ä½œæµç¨‹")
    print("=" * 60)
    
    api_key = "test-key"
    translator = SemanticTranslator(api_key)
    
    test_text = "The naiveHobo/InvoiceNet library processes invoices using TensorFlow and PyTorch."
    
    print(f"æµ‹è¯•æ–‡æœ¬: {test_text}")
    
    try:
        # ä½¿ç”¨AIä¿æŠ¤ç‰¹æ®Šåç§°
        protected_text, noun_mapping = translator._protect_special_names_with_ai(test_text)
        
        print(f"ä¿æŠ¤åæ–‡æœ¬: {protected_text}")
        print(f"æ˜ å°„è¡¨: {noun_mapping}")
        
        # æ¨¡æ‹Ÿç¿»è¯‘åçš„æ–‡æœ¬
        translated_text = "naiveHobo/InvoiceNet åº“ä½¿ç”¨ TensorFlow å’Œ PyTorch å¤„ç†å‘ç¥¨ã€‚"
        
        # æ¢å¤ç‰¹æ®Šåç§°
        restored_text = translator._restore_proper_nouns(translated_text, noun_mapping)
        
        print(f"æ¢å¤åæ–‡æœ¬: {restored_text}")
        
        print("\nâœ… AIä¿æŠ¤å·¥ä½œæµç¨‹æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ å·¥ä½œæµç¨‹æµ‹è¯•å¤±è´¥: {str(e)}")

def test_combined_protection():
    """æµ‹è¯•ç»„åˆä¿æŠ¤ï¼ˆAI + ä¼ ç»Ÿï¼‰"""
    print("\nğŸ§ª æµ‹è¯•ç»„åˆä¿æŠ¤åŠŸèƒ½")
    print("=" * 60)
    
    api_key = "test-key"
    translator = SemanticTranslator(api_key)
    
    test_text = "GitHub hosts naiveHobo/InvoiceNet, which uses Python and TensorFlow."
    
    print(f"æµ‹è¯•æ–‡æœ¬: {test_text}")
    
    try:
        # AIæ™ºèƒ½ä¿æŠ¤
        protected_text, ai_mapping = translator._protect_special_names_with_ai(test_text)
        print(f"AIä¿æŠ¤å: {protected_text}")
        print(f"AIæ˜ å°„: {ai_mapping}")
        
        # ä¼ ç»Ÿä¸“æœ‰åè¯ä¿æŠ¤
        protected_text, traditional_mapping = translator._protect_proper_nouns(protected_text)
        print(f"ä¼ ç»Ÿä¿æŠ¤å: {protected_text}")
        print(f"ä¼ ç»Ÿæ˜ å°„: {traditional_mapping}")
        
        # åˆå¹¶æ˜ å°„
        combined_mapping = {**ai_mapping, **traditional_mapping}
        print(f"åˆå¹¶æ˜ å°„: {combined_mapping}")
        
        print("\nâœ… ç»„åˆä¿æŠ¤åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ ç»„åˆä¿æŠ¤æµ‹è¯•å¤±è´¥: {str(e)}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ AIæ™ºèƒ½è¯†åˆ«ç‰¹æ®Šåç§°åŠŸèƒ½æµ‹è¯•")
    print("=" * 80)
    
    try:
        # æµ‹è¯•AIè¯†åˆ«åŠŸèƒ½
        test_ai_special_name_identification()
        
        # æµ‹è¯•AIä¿æŠ¤å·¥ä½œæµç¨‹
        test_ai_protection_workflow()
        
        # æµ‹è¯•ç»„åˆä¿æŠ¤
        test_combined_protection()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("\nğŸ’¡ æ³¨æ„ï¼šå®é™…ä½¿ç”¨æ—¶éœ€è¦æœ‰æ•ˆçš„OpenAI APIå¯†é’¥")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main()
