"""
æ€§èƒ½ä¼˜åŒ–å™¨ - æå‡ç¿»è¯‘é€Ÿåº¦
"""

import time
from typing import List, Dict, Any
import streamlit as st

class PerformanceOptimizer:
    """æ€§èƒ½ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.cache = {}  # ç¿»è¯‘ç¼“å­˜
        self.batch_size = 5  # æ‰¹å¤„ç†å¤§å°
        self.max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
    
    def optimize_translation_process(self, content_items: List[Dict], target_lang: str, translator) -> List[Dict]:
        """ä¼˜åŒ–ç¿»è¯‘æµç¨‹"""
        st.info("ğŸš€ å¯ç”¨æ€§èƒ½ä¼˜åŒ–æ¨¡å¼...")
        
        # 1. æ‰¹é‡é¢„å¤„ç†
        st.info("ğŸ“¦ æ‰¹é‡é¢„å¤„ç†å†…å®¹...")
        processed_items = self._batch_preprocess(content_items)
        
        # 2. æ™ºèƒ½ç¼“å­˜æ£€æŸ¥
        st.info("ğŸ’¾ æ£€æŸ¥ç¿»è¯‘ç¼“å­˜...")
        cached_items, uncached_items = self._check_cache(processed_items)
        
        # 3. æ‰¹é‡ç¿»è¯‘
        if uncached_items:
            st.info(f"ğŸ”„ æ‰¹é‡ç¿»è¯‘ {len(uncached_items)} é¡¹å†…å®¹...")
            translated_items = self._batch_translate(uncached_items, target_lang, translator)
            
            # æ›´æ–°ç¼“å­˜
            self._update_cache(translated_items)
        else:
            translated_items = []
        
        # 4. åˆå¹¶ç»“æœ
        all_translated = cached_items + translated_items
        
        # 5. æ€§èƒ½ç»Ÿè®¡
        self._show_performance_stats(len(content_items), len(cached_items), len(translated_items))
        
        return all_translated
    
    def _batch_preprocess(self, content_items: List[Dict]) -> List[Dict]:
        """æ‰¹é‡é¢„å¤„ç†å†…å®¹"""
        processed_items = []
        
        for item in content_items:
            # é¢„å¤„ç†æ–‡æœ¬
            processed_item = {
                **item,
                'processed_text': item.get('text', '').strip(),
                'text_length': len(item.get('text', '')),
                'is_short': len(item.get('text', '')) < 50,
                'is_long': len(item.get('text', '')) > 200
            }
            processed_items.append(processed_item)
        
        return processed_items
    
    def _check_cache(self, items: List[Dict]) -> tuple:
        """æ£€æŸ¥ç¿»è¯‘ç¼“å­˜"""
        cached_items = []
        uncached_items = []
        
        for item in items:
            text_key = item.get('processed_text', '')
            cache_key = f"{text_key}_{item.get('type', '')}"
            
            if cache_key in self.cache:
                # ä½¿ç”¨ç¼“å­˜
                cached_item = {**item, 'translated_text': self.cache[cache_key]}
                cached_items.append(cached_item)
            else:
                # éœ€è¦ç¿»è¯‘
                uncached_items.append(item)
        
        return cached_items, uncached_items
    
    def _batch_translate(self, items: List[Dict], target_lang: str, translator) -> List[Dict]:
        """æ‰¹é‡ç¿»è¯‘"""
        translated_items = []
        
        # æŒ‰é•¿åº¦åˆ†ç»„
        short_items = [item for item in items if item.get('is_short', False)]
        long_items = [item for item in items if item.get('is_long', False)]
        medium_items = [item for item in items if not item.get('is_short', False) and not item.get('is_long', False)]
        
        # çŸ­æ–‡æœ¬æ‰¹é‡å¤„ç†
        if short_items:
            translated_items.extend(self._translate_short_texts(short_items, target_lang, translator))
        
        # ä¸­ç­‰é•¿åº¦æ–‡æœ¬
        if medium_items:
            translated_items.extend(self._translate_medium_texts(medium_items, target_lang, translator))
        
        # é•¿æ–‡æœ¬å•ç‹¬å¤„ç†
        if long_items:
            translated_items.extend(self._translate_long_texts(long_items, target_lang, translator))
        
        return translated_items
    
    def _translate_short_texts(self, items: List[Dict], target_lang: str, translator) -> List[Dict]:
        """ç¿»è¯‘çŸ­æ–‡æœ¬ï¼ˆæ‰¹é‡ï¼‰"""
        if not items:
            return []
        
        # åˆå¹¶çŸ­æ–‡æœ¬è¿›è¡Œæ‰¹é‡ç¿»è¯‘
        combined_text = " | ".join([item.get('processed_text', '') for item in items])
        
        try:
            # æ‰¹é‡ç¿»è¯‘
            translated_combined = translator._translate_paragraph_simple(combined_text, target_lang)
            
            # åˆ†å‰²ç»“æœ
            translated_parts = translated_combined.split(" | ")
            
            translated_items = []
            for i, item in enumerate(items):
                translated_text = translated_parts[i] if i < len(translated_parts) else item.get('processed_text', '')
                translated_items.append({
                    **item,
                    'translated_text': translated_text
                })
            
            return translated_items
            
        except Exception as e:
            st.warning(f"æ‰¹é‡ç¿»è¯‘çŸ­æ–‡æœ¬å¤±è´¥: {str(e)}")
            # å›é€€åˆ°å•ç‹¬ç¿»è¯‘
            return self._translate_individually(items, target_lang, translator)
    
    def _translate_medium_texts(self, items: List[Dict], target_lang: str, translator) -> List[Dict]:
        """ç¿»è¯‘ä¸­ç­‰é•¿åº¦æ–‡æœ¬"""
        return self._translate_individually(items, target_lang, translator)
    
    def _translate_long_texts(self, items: List[Dict], target_lang: str, translator) -> List[Dict]:
        """ç¿»è¯‘é•¿æ–‡æœ¬"""
        return self._translate_individually(items, target_lang, translator)
    
    def _translate_individually(self, items: List[Dict], target_lang: str, translator) -> List[Dict]:
        """å•ç‹¬ç¿»è¯‘æ¯ä¸ªé¡¹ç›®"""
        translated_items = []
        
        for i, item in enumerate(items):
            try:
                # æ˜¾ç¤ºè¿›åº¦
                if i % 5 == 0:
                    st.info(f"æ­£åœ¨ç¿»è¯‘ç¬¬ {i+1}/{len(items)} é¡¹...")
                
                # ç¿»è¯‘
                if item.get('type') == 'paragraph':
                    translated_text = translator._translate_paragraph_simple(item.get('processed_text', ''), target_lang)
                elif item.get('type') == 'table_cell':
                    translated_text = translator._translate_table_cell_simple(item.get('processed_text', ''), target_lang)
                else:
                    translated_text = item.get('processed_text', '')
                
                translated_items.append({
                    **item,
                    'translated_text': translated_text
                })
                
            except Exception as e:
                st.warning(f"ç¿»è¯‘ç¬¬ {i+1} é¡¹å¤±è´¥: {str(e)}")
                translated_items.append({
                    **item,
                    'translated_text': item.get('processed_text', '')
                })
        
        return translated_items
    
    def _update_cache(self, translated_items: List[Dict]):
        """æ›´æ–°ç¼“å­˜"""
        for item in translated_items:
            text_key = item.get('processed_text', '')
            cache_key = f"{text_key}_{item.get('type', '')}"
            self.cache[cache_key] = item.get('translated_text', '')
    
    def _show_performance_stats(self, total_items: int, cached_items: int, translated_items: int):
        """æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡"""
        cache_hit_rate = (cached_items / total_items * 100) if total_items > 0 else 0
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("æ€»é¡¹ç›®æ•°", total_items)
        
        with col2:
            st.metric("ç¼“å­˜å‘½ä¸­", cached_items)
        
        with col3:
            st.metric("æ–°ç¿»è¯‘", translated_items)
        
        with col4:
            st.metric("ç¼“å­˜å‘½ä¸­ç‡", f"{cache_hit_rate:.1f}%")
        
        if cache_hit_rate > 50:
            st.success(f"ğŸ‰ ç¼“å­˜å‘½ä¸­ç‡ {cache_hit_rate:.1f}%ï¼Œæ€§èƒ½ä¼˜åŒ–æ•ˆæœæ˜¾è‘—ï¼")
        elif cache_hit_rate > 20:
            st.info(f"ğŸ“ˆ ç¼“å­˜å‘½ä¸­ç‡ {cache_hit_rate:.1f}%ï¼Œæ€§èƒ½æœ‰æ‰€æå‡")
        else:
            st.warning(f"âš ï¸ ç¼“å­˜å‘½ä¸­ç‡ {cache_hit_rate:.1f}%ï¼Œå»ºè®®å¢åŠ ç¼“å­˜å†…å®¹")

class FastTranslator:
    """å¿«é€Ÿç¿»è¯‘å™¨ - ç®€åŒ–ç‰ˆç¿»è¯‘é€»è¾‘"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        import openai
        openai.api_key = api_key
    
    def _translate_paragraph_simple(self, text: str, target_lang: str) -> str:
        """ç®€åŒ–çš„æ®µè½ç¿»è¯‘"""
        try:
            import openai
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": f"Translate the following text to {target_lang}. Keep technical terms, proper nouns, and special names unchanged."},
                    {"role": "user", "content": text}
                ],
                max_tokens=500,
                temperature=0.1
            )
            return response.choices[0].message.content
        except Exception as e:
            return text
    
    def _translate_table_cell_simple(self, text: str, target_lang: str) -> str:
        """ç®€åŒ–çš„è¡¨æ ¼å•å…ƒæ ¼ç¿»è¯‘"""
        return self._translate_paragraph_simple(text, target_lang)
